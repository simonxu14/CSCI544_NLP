Assignment 1 Report

Name: Xinlong Xu
USC-ID: 7860029645

1. Performance on the development data with 100% of the training data
1a. spam precision: 0.9928
1b. spam recall:    0.9780
1c. spam F1 score:  0.9853
1d. ham precision:  0.9479
1e. ham recall:     0.9827
1f. ham F1 score:   0.9650

2. Performance on the development data with 10% of the training data
2a. spam precision: 0.9870
2b. spam recall:    0.9532
2c. spam F1 score:  0.9698
2d. ham precision:  0.8942
2e. ham recall:     0.9693
2f. ham F1 score:   0.9302

3. Description of enhancement(s) you tried (e.g., different approach(es) to smoothing, treating common words differently, dealing with unknown words differently):
I treat common words differently. For example, I pick up the word which appears many times in both ham and spam. If the probability of occurrence of that word in ham is almost the same as in spam, I put that word in a list named common_word and store the list in nbmodel.txt. When classify a new email and check each word, if the word is in the common_word list, I ignore the word and continue to check the next word. I found it really improve the precision, recall and f1 of both ham and spam.

4. Best performance results based on enhancements. Note that these could be the same or worse than the standard implementation.
4a. spam precision: 0.9918
4b. spam recall:    0.9907
4c. spam F1 score:  0.9913
4d. ham precision:  0.9774
4e. ham recall:     0.9800
4f. ham F1 score:   0.9787